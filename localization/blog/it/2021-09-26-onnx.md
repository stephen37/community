---
id: 2021-09-26-onnx.md
title: Process Models with ONNX
date: 2021-09-26T00:00:00.000Z
desc: how to use multiple models for image search based on ONNX and Milvus
cover: assets.zilliz.com/medium_1_cfb009269a.png
tag: Engineering
canonicalUrl: >-
  https://zilliz.com/blog/combine-ai-models-for-image-search-using-onnx-and-milvus
---
<custom-h1>Combine AI Models for Image Search using ONNX and Milvus</custom-h1><p>Open Neural Network Exchange (ONNX) is an open format built to represent machine learning models. Since it was open-sourced in 2017, ONNX has developed into a standard for AI, providing building blocks for machine learning and deep learning models. ONNX defines a common file format to enable AI developers to use models with various frameworks, tools, runtimes, and compilers, and helps increase the speed of innovation in the artificial intelligence community.</p>
<p>Milvus is an open-source vector database that is highly flexible, reliable and blazing fast. It supports adding, deleting, updating and near real-time search of vector. Milvus has a comprehensive set of intuitive APIs, and support for multiple widely adopted index libraries (e.g. Faiss, NMSLIB, and Annoy), simplifying the index selection for a given scenario. Milvus is simple to use, and it has been used in hundreds of organizations and institutions worldwide, including image, audio and video search, recommendation, chatbot, new drug search, etc.</p>
<p>This article will introduce you how to use multiple models for image search based on ONNX and Milvus. It takes VGG16 and ResNet50 models as examples, uses ONNX to run different AI models to generate feature vectors, and finally performs feature vector retrieval in Milvus to return similar images.</p>
<h2 id="Process-Models-with-ONNX" class="common-anchor-header">Process Models with ONNX<button data-href="#Process-Models-with-ONNX" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>The ONNX format can be easily exchanged between AI models. For example, the TensorFlow model can be converted to ONNX format and run in the Caffe environment. In this example, we convert the pre-trained ResNet50 model under the Keras framework to the ONNX format, and then call the VGG16 model in ONNX format to analyze different models.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> keras.applications.resnet50 <span class="hljs-keyword">import</span> ResNet50
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># load keras-resnet50 model and save as a floder</span>
model_resnet50 = ResNet50(include_top=<span class="hljs-literal">False</span>, pooling=<span class="hljs-string">&#x27;max&#x27;</span>, weights=<span class="hljs-string">&#x27;imagenet&#x27;</span>)
tf.saved_model.save(model_resnet50, <span class="hljs-string">&quot;keras_resnet50_model&quot;</span>)

<span class="hljs-comment"># convert resnet50 model to onnx</span>
! python -m tf2onnx.convert --saved-model <span class="hljs-string">&quot;keras_resnet50_model&quot;</span> --output <span class="hljs-string">&quot;onnx_resnet50.onnx&quot;</span>
<button class="copy-code-btn"></button></code></pre>
<p>Note: When we used the interface <code translate="no">keras2onnx.convert_keras(model, model.name)</code> to convert the model, it will return the error <code translate="no">AttributeError:'KerasTensor' object has no attribute'graph'</code>. Then we can use Pythonâ€™s Bash command to convert according to the solution on Stack Overflow.</p>
<h2 id="Extract-Feature-Vectors-using-Models" class="common-anchor-header">Extract Feature Vectors using Models<button data-href="#Extract-Feature-Vectors-using-Models" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>After converting ResNet50 model into ONNX format, you can extract the feature vector of the picture directly through the inference. Note: Feature vectors need to be normalized after extraction.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># get the image vectors with onnx model</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_onnx_vectors</span>(<span class="hljs-params">onnx_model, img_path</span>):
    img = image.load_img(img_path, target_size=(<span class="hljs-number">224</span>, <span class="hljs-number">224</span>))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=<span class="hljs-number">0</span>)
    x = preprocess_input(x)
    
    sess = onnxruntime.InferenceSession(onnx_model)
    x = x <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(x, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">else</span> [x]
    feed = <span class="hljs-built_in">dict</span>([(<span class="hljs-built_in">input</span>.name, x[n]) <span class="hljs-keyword">for</span> n, <span class="hljs-built_in">input</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sess.get_inputs())])
    feat = sess.run(<span class="hljs-literal">None</span>, feed)[<span class="hljs-number">0</span>]
    
    norm_feat = feat[<span class="hljs-number">0</span>] / LA.norm(feat[<span class="hljs-number">0</span>])
    norm_feat = [i.item() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> norm_feat]
    <span class="hljs-keyword">return</span> norm_feat
<button class="copy-code-btn"></button></code></pre>
<p>Use ONNX-formatted VGG16 model to process image data:</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># generate vectors with ResNet50 and VGG16 ONNX model</span>
2vec_resnet = get_onnx_vectors(<span class="hljs-string">&quot;onnx_resnet50.onnx&quot;</span>, <span class="hljs-string">&quot;./pic/example.jpg&quot;</span>)
3vec_vgg = get_onnx_vectors(<span class="hljs-string">&quot;onnx_vgg16.onnx&quot;</span>, <span class="hljs-string">&quot;./pic/example.jpg&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Store-Vector-Data" class="common-anchor-header">Store Vector Data<button data-href="#Store-Vector-Data" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Unstructured data such as pictures cannot be directly processed by computer, but it can be converted into vectors through AI model and then analyzed by a computer. Milvus vector database is designed power massive unstructured data analysis. It can store vector data and perform near real-time analysis. First, create a collection of the corresponding model in Milvus, and then insert the image vectors.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> milvus <span class="hljs-keyword">import</span> *

<span class="hljs-comment"># create collections in Milvus</span>
milvus.create_collection(resnet_collection_param)
milvus.create_collection(vgg_collection_param)

<span class="hljs-comment"># insert data to Milvus and return ids</span>
status, resnet_ids = milvus.insert(resnet_collection_name, resnet_vectors)
status, vgg_ids = milvus.insert(vgg_collection_name, vgg_vectors)
<button class="copy-code-btn"></button></code></pre>
<p>After inserting the data successfully, Milvus will return the ID corresponding to the vector, and then we can find the picture by ID. Since Milvus 1.1 used in this case does not support scalar filtering (which Milvus 2.0 now supports), Redis is used to store the vector ID and the key-value of the image path.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> redis
<span class="hljs-keyword">def</span> <span class="hljs-title function_">img_ids_to_redis</span>(<span class="hljs-params">img_directory, res_ids</span>):
  <span class="hljs-keyword">for</span> img, ids <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(images, res_ids):
    redis.<span class="hljs-built_in">set</span>(ids, img)
<button class="copy-code-btn"></button></code></pre>
<h2 id="Search-for-Similar-Images" class="common-anchor-header">Search for Similar Images<button data-href="#Search-for-Similar-Images" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>After storing the data, we can retrieve the vector. Milvus supports multiple distance calculation methods, including Euclidean, inner product and Hamming distance. The image similarity search in this article adopts the Euclidean distance calculation between the vectors in Milvus, returns the similar vector ID, and then finds the image corresponding to the ID in Redis.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># search in Milvus and return the similarly results with ids</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">search_in_milvus</span>(<span class="hljs-params">collection_name, search_vector</span>):
    status, results = milvus.search(collection_name, TOP_K, [search_vector])
    <span class="hljs-built_in">print</span>(status)
    re_ids = [x.<span class="hljs-built_in">id</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
    re_distance = [x.distance <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results[<span class="hljs-number">0</span>]]
    <span class="hljs-keyword">return</span> re_ids, re_distance
    
<span class="hljs-comment"># get the images according the result ids</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_sim_imgs</span>(<span class="hljs-params">collection_name, search_vector</span>):
    ids, distance = search_in_milvus(collection_name, search_vector)
    img = [red.get(i).decode(<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ids]
    <span class="hljs-keyword">return</span> ids, distance, img
<button class="copy-code-btn"></button></code></pre>
<p>Taking the VGG16 and ResNet50 models as examples, this article shows processing multiple models through ONNX and combining multiple models with Milvus for similar vector retrieval to get similar images. The above two models are based on the Keras framework, which can quickly extract feature vectors. It can be seen from the Notebook that although the results of Milvusâ€™s search for pictures on the COCO dataset based on these two models are similar, their Euclidean distances are not the same. You can also try to compare the search results of the two models using other datasets.</p>
<p>Milvus is a high-performance, highly available vector database that can be used to process feature vectors generated from massive unstructured data. For more solutions, you can refer to <a href="https://github.com/milvus-io/bootcamp">Milvus bootcamp</a>.</p>
<h2 id="References" class="common-anchor-header">References<button data-href="#References" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ol>
<li>https://github.com/onnx/onnx</li>
<li>https://onnx.ai/</li>
<li>https://milvus.io/cn/</li>
<li>https://github.com/milvus-io/bootcamp</li>
</ol>
<h3 id="About-author" class="common-anchor-header">About author</h3><p>Shiyu Chen, a data engineer at Zilliz, graduated from Xidian University with a degree in Computer Science. Since joining Zilliz, she has been exploring solutions for Milvus in various fields, such as audio and video analysis, molecule formula retrieval, etc., which has greatly enriched the application scenarios of the community. She is currently exploring more interesting solutions. In her spare time, she loves sports and reading.</p>
